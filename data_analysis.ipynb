{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis Project\n",
        "## MySQL Database and Excel File Analysis\n",
        "\n",
        "This notebook provides tools and examples for analysing data from:\n",
        "- MySQL databases\n",
        "- Excel files (.xlsx, .xls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Libraries\n",
        "\n",
        "Run this cell to install necessary packages if not already installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install pandas numpy mysql-connector-python sqlalchemy openpyxl matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine, text\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "import warnings\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style (tries multiple styles for compatibility)\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except OSError:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except OSError:\n",
        "        plt.style.use('ggplot')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MySQL Database Connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MySQL Database Configuration\n",
        "# Update these values with your database credentials\n",
        "\n",
        "MYSQL_CONFIG = {\n",
        "    'host': 'localhost',\n",
        "    'database': 'your_database_name',\n",
        "    'user': 'your_username',\n",
        "    'password': 'your_password',\n",
        "    'port': 3306\n",
        "}\n",
        "\n",
        "# Create connection string for SQLAlchemy\n",
        "CONNECTION_STRING = f\"mysql+mysqlconnector://{MYSQL_CONFIG['user']}:{MYSQL_CONFIG['password']}@{MYSQL_CONFIG['host']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database']}\"\n",
        "\n",
        "print(\"Configuration set. Update the credentials above before connecting.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Test MySQL Connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_mysql_connection(config):\n",
        "    \"\"\"Test MySQL database connection\"\"\"\n",
        "    try:\n",
        "        connection = mysql.connector.connect(**config)\n",
        "        if connection.is_connected():\n",
        "            db_info = connection.get_server_info()\n",
        "            print(f\"✓ Successfully connected to MySQL Server version {db_info}\")\n",
        "            cursor = connection.cursor()\n",
        "            cursor.execute(\"SELECT DATABASE();\")\n",
        "            record = cursor.fetchone()\n",
        "            print(f\"✓ Connected to database: {record[0]}\")\n",
        "            cursor.close()\n",
        "            connection.close()\n",
        "            return True\n",
        "    except Error as e:\n",
        "        print(f\"✗ Error connecting to MySQL: {e}\")\n",
        "        return False\n",
        "\n",
        "# Uncomment to test connection\n",
        "# test_mysql_connection(MYSQL_CONFIG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Query MySQL Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_mysql(query, connection_string=None):\n",
        "    \"\"\"\n",
        "    Execute a SQL query and return results as a pandas DataFrame\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    query : str\n",
        "        SQL query to execute\n",
        "    connection_string : str, optional\n",
        "        Database connection string. If None, uses CONNECTION_STRING\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Query results as a DataFrame\n",
        "    \"\"\"\n",
        "    if connection_string is None:\n",
        "        connection_string = CONNECTION_STRING\n",
        "    \n",
        "    try:\n",
        "        engine = create_engine(connection_string)\n",
        "        df = pd.read_sql(query, engine)\n",
        "        engine.dispose()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing query: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Query all tables in the database\n",
        "# query = \"SHOW TABLES;\"\n",
        "# tables = query_mysql(query)\n",
        "# print(tables)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Example: Load Data from MySQL Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load data from a specific table\n",
        "# Replace 'your_table_name' with your actual table name\n",
        "\n",
        "# table_name = 'your_table_name'\n",
        "# query = f\"SELECT * FROM {table_name} LIMIT 1000;\"\n",
        "# df_mysql = query_mysql(query)\n",
        "# print(f\"Loaded {len(df_mysql)} rows from MySQL\")\n",
        "# df_mysql.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Excel File Operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Read Excel File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_excel_file(file_path, sheet_name=None, header=0, skiprows=None, nrows=None):\n",
        "    \"\"\"\n",
        "    Read an Excel file and return as pandas DataFrame\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    file_path : str\n",
        "        Path to the Excel file\n",
        "    sheet_name : str, int, or list, optional\n",
        "        Sheet name(s) to read. Default is first sheet\n",
        "    header : int, optional\n",
        "        Row to use as column names (0-indexed)\n",
        "    skiprows : int or list, optional\n",
        "        Rows to skip at the start\n",
        "    nrows : int, optional\n",
        "        Number of rows to read\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame or dict\n",
        "        DataFrame if single sheet, dict of DataFrames if multiple sheets\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if sheet_name is None:\n",
        "            # Read first sheet\n",
        "            df = pd.read_excel(file_path, header=header, skiprows=skiprows, nrows=nrows)\n",
        "            return df\n",
        "        else:\n",
        "            # Read specific sheet(s)\n",
        "            if isinstance(sheet_name, list):\n",
        "                # Multiple sheets\n",
        "                dfs = pd.read_excel(file_path, sheet_name=sheet_name, header=header, skiprows=skiprows, nrows=nrows)\n",
        "                return dfs\n",
        "            else:\n",
        "                # Single sheet\n",
        "                df = pd.read_excel(file_path, sheet_name=sheet_name, header=header, skiprows=skiprows, nrows=nrows)\n",
        "                return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading Excel file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Read Excel file\n",
        "# excel_file_path = 'path/to/your/file.xlsx'\n",
        "# df_excel = read_excel_file(excel_file_path)\n",
        "# print(f\"Loaded {len(df_excel)} rows from Excel\")\n",
        "# df_excel.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Read Multiple Sheets from Excel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_all_excel_sheets(file_path):\n",
        "    \"\"\"\n",
        "    Read all sheets from an Excel file\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    file_path : str\n",
        "        Path to the Excel file\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary with sheet names as keys and DataFrames as values\n",
        "    \"\"\"\n",
        "    try:\n",
        "        excel_file = pd.ExcelFile(file_path)\n",
        "        sheet_names = excel_file.sheet_names\n",
        "        print(f\"Found {len(sheet_names)} sheet(s): {sheet_names}\")\n",
        "        \n",
        "        dfs = {}\n",
        "        for sheet in sheet_names:\n",
        "            dfs[sheet] = pd.read_excel(excel_file, sheet_name=sheet)\n",
        "            print(f\"  - {sheet}: {len(dfs[sheet])} rows, {len(dfs[sheet].columns)} columns\")\n",
        "        \n",
        "        return dfs\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading Excel file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example: Read all sheets\n",
        "# excel_file_path = 'path/to/your/file.xlsx'\n",
        "# all_sheets = read_all_excel_sheets(excel_file_path)\n",
        "# # Access specific sheet: all_sheets['Sheet1']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Exploration and Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Basic Data Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def explore_data(df, name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Display comprehensive information about a DataFrame\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame to explore\n",
        "    name : str\n",
        "        Name of the dataset for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"=\" * 60)\n",
        "    print(f\"Data Exploration: {name}\")\n",
        "    print(f\"=\" * 60)\n",
        "    \n",
        "    print(f\"\\nShape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "    \n",
        "    print(f\"\\nColumn Names and Types:\")\n",
        "    print(df.dtypes)\n",
        "    \n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    print(f\"\\nLast 5 rows:\")\n",
        "    print(df.tail())\n",
        "    \n",
        "    print(f\"\\nBasic Statistics:\")\n",
        "    print(df.describe())\n",
        "    \n",
        "    print(f\"\\nMissing Values:\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df)) * 100\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Count': missing,\n",
        "        'Missing Percentage': missing_pct\n",
        "    })\n",
        "    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "    if len(missing_df) > 0:\n",
        "        print(missing_df)\n",
        "    else:\n",
        "        print(\"No missing values!\")\n",
        "    \n",
        "    print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Example usage:\n",
        "# explore_data(df_mysql, \"MySQL Data\")\n",
        "# explore_data(df_excel, \"Excel Data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Data Cleaning Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_data(df, drop_duplicates=True, handle_missing='drop', fill_value=None):\n",
        "    \"\"\"\n",
        "    Clean DataFrame by removing duplicates and handling missing values\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame to clean\n",
        "    drop_duplicates : bool\n",
        "        Whether to remove duplicate rows\n",
        "    handle_missing : str\n",
        "        'drop' to drop rows with missing values,\n",
        "        'fill' to fill with fill_value,\n",
        "        'keep' to keep as is\n",
        "    fill_value : any\n",
        "        Value to fill missing values with (if handle_missing='fill')\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Cleaned DataFrame\n",
        "    \"\"\"\n",
        "    df_cleaned = df.copy()\n",
        "    \n",
        "    if drop_duplicates:\n",
        "        before = len(df_cleaned)\n",
        "        df_cleaned = df_cleaned.drop_duplicates()\n",
        "        after = len(df_cleaned)\n",
        "        print(f\"Removed {before - after} duplicate rows\")\n",
        "    \n",
        "    if handle_missing == 'drop':\n",
        "        before = len(df_cleaned)\n",
        "        df_cleaned = df_cleaned.dropna()\n",
        "        after = len(df_cleaned)\n",
        "        print(f\"Removed {before - after} rows with missing values\")\n",
        "    elif handle_missing == 'fill':\n",
        "        df_cleaned = df_cleaned.fillna(fill_value)\n",
        "        print(f\"Filled missing values with {fill_value}\")\n",
        "    \n",
        "    return df_cleaned\n",
        "\n",
        "# Example usage:\n",
        "# df_cleaned = clean_data(df_excel, drop_duplicates=True, handle_missing='fill', fill_value=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Data Analysis Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Group by and aggregate\n",
        "# df_grouped = df.groupby('column_name').agg({\n",
        "#     'numeric_column': ['sum', 'mean', 'count']\n",
        "# })\n",
        "# print(df_grouped)\n",
        "\n",
        "# Example 2: Filter data\n",
        "# df_filtered = df[df['column_name'] > threshold]\n",
        "# print(f\"Filtered to {len(df_filtered)} rows\")\n",
        "\n",
        "# Example 3: Calculate statistics by category\n",
        "# stats_by_category = df.groupby('category_column').agg({\n",
        "#     'numeric_column': ['mean', 'std', 'min', 'max']\n",
        "# })\n",
        "# print(stats_by_category)\n",
        "\n",
        "# Example 4: Pivot table\n",
        "# pivot_table = pd.pivot_table(df, \n",
        "#                              values='value_column',\n",
        "#                              index='row_column',\n",
        "#                              columns='column_column',\n",
        "#                              aggfunc='mean')\n",
        "# print(pivot_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Visualisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_numeric_distribution(df, column, bins=30, figsize=(10, 6)):\n",
        "    \"\"\"Plot distribution of a numeric column\"\"\"\n",
        "    if column not in df.columns:\n",
        "        print(f\"Column '{column}' not found in DataFrame\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
        "    \n",
        "    # Histogram\n",
        "    axes[0].hist(df[column].dropna(), bins=bins, edgecolor='black', alpha=0.7)\n",
        "    axes[0].set_title(f'Distribution of {column}')\n",
        "    axes[0].set_xlabel(column)\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    \n",
        "    # Box plot\n",
        "    axes[1].boxplot(df[column].dropna())\n",
        "    axes[1].set_title(f'Box Plot of {column}')\n",
        "    axes[1].set_ylabel(column)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# plot_numeric_distribution(df, 'numeric_column')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_categorical_counts(df, column, top_n=10, figsize=(10, 6)):\n",
        "    \"\"\"Plot counts of categorical values\"\"\"\n",
        "    if column not in df.columns:\n",
        "        print(f\"Column '{column}' not found in DataFrame\")\n",
        "        return\n",
        "    \n",
        "    value_counts = df[column].value_counts().head(top_n)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    value_counts.plot(kind='bar', color='steelblue', edgecolor='black')\n",
        "    plt.title(f'Top {top_n} Values in {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# plot_categorical_counts(df, 'category_column', top_n=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_correlation_heatmap(df, figsize=(12, 10)):\n",
        "    \"\"\"Plot correlation heatmap for numeric columns\"\"\"\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    \n",
        "    if len(numeric_df.columns) < 2:\n",
        "        print(\"Need at least 2 numeric columns for correlation\")\n",
        "        return\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# plot_correlation_heatmap(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Combining MySQL and Excel Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_dataframes(df1, df2, on=None, how='inner', suffixes=('_x', '_y')):\n",
        "    \"\"\"\n",
        "    Merge two DataFrames\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df1, df2 : pd.DataFrame\n",
        "        DataFrames to merge\n",
        "    on : str or list\n",
        "        Column(s) to join on\n",
        "    how : str\n",
        "        Type of merge: 'left', 'right', 'outer', 'inner'\n",
        "    suffixes : tuple\n",
        "        Suffixes to apply to overlapping column names\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Merged DataFrame\n",
        "    \"\"\"\n",
        "    merged = pd.merge(df1, df2, on=on, how=how, suffixes=suffixes)\n",
        "    print(f\"Merged: {len(df1)} rows × {len(df2)} rows → {len(merged)} rows\")\n",
        "    return merged\n",
        "\n",
        "# Example: Merge MySQL data with Excel data\n",
        "# df_combined = merge_dataframes(df_mysql, df_excel, on='common_column', how='inner')\n",
        "# df_combined.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_to_excel(df, file_path, sheet_name='Sheet1', index=False):\n",
        "    \"\"\"Export DataFrame to Excel file\"\"\"\n",
        "    try:\n",
        "        df.to_excel(file_path, sheet_name=sheet_name, index=index)\n",
        "        print(f\"✓ Successfully exported to {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error exporting to Excel: {e}\")\n",
        "\n",
        "def export_to_csv(df, file_path, index=False):\n",
        "    \"\"\"Export DataFrame to CSV file\"\"\"\n",
        "    try:\n",
        "        df.to_csv(file_path, index=index)\n",
        "        print(f\"✓ Successfully exported to {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error exporting to CSV: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "# export_to_excel(df_combined, 'output/analysis_results.xlsx', sheet_name='Results')\n",
        "# export_to_csv(df_combined, 'output/analysis_results.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Your Analysis\n",
        "\n",
        "Add your custom analysis code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your data here\n",
        "# Example:\n",
        "# df_mysql = query_mysql(\"SELECT * FROM your_table LIMIT 1000;\")\n",
        "# df_excel = read_excel_file('path/to/your/file.xlsx')\n",
        "\n",
        "# Perform your analysis\n",
        "# Example:\n",
        "# explore_data(df_mysql, \"MySQL Data\")\n",
        "# explore_data(df_excel, \"Excel Data\")\n",
        "\n",
        "# Visualise your data\n",
        "# Example:\n",
        "# plot_numeric_distribution(df, 'column_name')\n",
        "# plot_correlation_heatmap(df)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
